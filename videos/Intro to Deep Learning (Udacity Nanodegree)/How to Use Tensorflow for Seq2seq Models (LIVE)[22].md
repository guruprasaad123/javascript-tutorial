Let's build a Sequence to Sequence model in Tensorflow to learn exactly how they work. You can use this model to make chatbots, language translators, text generators, and much more . We'll go over memory, attention, and some variants (like bidirectional layers) both programmatically and mathematically.

Code for this video:
https://github.com/llSourcell/seq2seq_model_live/blob/master/2-seq2seq-advanced.ipynb

Please Subscribe! And like. And comment. That's what keeps me going. 

More Learning resources:
https://www.tensorflow.org/tutorials/seq2seq
http://www.kdnuggets.com/2015/06/rnn-tutorial-sequence-learning-recurrent-neural-networks.html
http://suriyadeepan.github.io/2016-06-28-easy-seq2seq/
https://indico.io/blog/sequence-modeling-neuralnets-part1/
http://www.wildml.com/2016/08/rnns-in-tensorflow-a-practical-guide-and-undocumented-features/

Join us in the Wizards Slack channel:
http://wizards.herokuapp.com/

Streaming Live from UploadVR's Studio in San Francisco!: https://www.youtube.com/uploadvr

And please support me on Patreon:
https://www.patreon.com/user?u=3191693
Follow me:
Twitter: https://twitter.com/sirajraval
Facebook: https://www.facebook.com/sirajology Instagram: https://www.instagram.com/sirajraval/ Instagram: https://www.instagram.com/sirajraval/ 
Signup for my newsletter for exciting updates in the field of AI:
https://goo.gl/FZzJ5w
Hit the Join button above to sign up to become a member of my channel for access to exclusive content!