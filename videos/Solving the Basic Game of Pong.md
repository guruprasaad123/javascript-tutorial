Building an AI to beat pong using just the pixels of the screen as input with no hard-coded rules? Yes, its possible. We'll solve this using an approach called "Policy Gradients" which is even more popular than Q-learning. I'll show you how its done using a mix of animations, code, and theory. Let's beat pong!

Code (and challenge) for this week:
https://github.com/llSourcell/policy_gradients_pong

Alex's Winning code:
https://github.com/msoedov/q-learner

Aditya's Runner up code:
https://github.com/avp1598/q_learning

Please Subscribe! And like. And comment. That's what keeps me going.

Want more inspiration & education? Connect with me:
Twitter: https://twitter.com/sirajraval
Instagram: https://www.instagram.com/llsourcell/
Facebook: https://www.facebook.com/sirajology

More learning resources:
http://karpathy.github.io/2016/05/31/rl/
https://medium.com/@awjuliani/super-simple-reinforcement-learning-tutorial-part-2-ded33892c724
http://minpy.readthedocs.io/en/latest/tutorial/rl_policy_gradient_tutorial/rl_policy_gradient.html
http://pemami4911.github.io/blog/2016/08/21/ddpg-rl.html
http://kvfrans.com/simple-algoritms-for-solving-cartpole/
https://theneuralperspective.com/2016/11/25/reinforcement-learning-rl-policy-gradients-i/

Join us in the Wizards Slack channel:
http://wizards.herokuapp.com/

And please support me on Patreon:
https://www.patreon.com/user?u=3191693